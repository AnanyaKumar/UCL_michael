{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/juice/scr/ananya/continual/UCL/models/__init__.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path = [module_path] + sys.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from augmentations import get_aug\n",
    "import models\n",
    "from tools import AverageMeter, knn_monitor, Logger, file_exist_check\n",
    "from datasets import get_dataset\n",
    "from datetime import datetime\n",
    "from utils.loggers import *\n",
    "from utils.metrics import mask_classes\n",
    "from utils.loggers import CsvLogger\n",
    "from datasets.utils.continual_dataset import ContinualDataset\n",
    "from models.utils.continual_model import ContinualModel\n",
    "from typing import Tuple\n",
    "import importlib\n",
    "\n",
    "import yaml\n",
    "from arguments import Namespace\n",
    "from types import SimpleNamespace\n",
    "import arguments\n",
    "importlib.reload(arguments)\n",
    "importlib.reload(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "\n",
    "def get_args(config_path):\n",
    "    args = {\n",
    "        'debug': True,\n",
    "        'debug_subset_size': 8,\n",
    "        'download': True,\n",
    "        'data_dir': '../Data/',\n",
    "        'log_dir': False,\n",
    "        'ckpt_dir': False,\n",
    "        'device': 'cuda',\n",
    "        'eval_from': None,\n",
    "        'hide_progress': True,\n",
    "        'cl_default': False,\n",
    "        'validation': True,\n",
    "    }\n",
    "    with open(config_path, 'r') as f:\n",
    "        for key, value in Namespace(yaml.load(f, Loader=yaml.FullLoader)).__dict__.items():\n",
    "            args[key] = value\n",
    "\n",
    "    args['aug_kwargs'] = {\n",
    "        'name': args['model'].name,\n",
    "        'image_size': args['dataset'].image_size\n",
    "    }\n",
    "    args['dataset_kwargs'] = {\n",
    "        'dataset':args['dataset'].name,\n",
    "        'data_dir': '../Data/',\n",
    "        'download': False,\n",
    "        'debug_subset_size': False,\n",
    "    }\n",
    "    args['dataloader_kwargs'] = {\n",
    "        'drop_last': True,\n",
    "        'pin_memory': True,\n",
    "        'num_workers': args['dataset'].num_workers,\n",
    "    }\n",
    "    args = SimpleNamespace(**args)\n",
    "    return args\n",
    "\n",
    "def load_model(path, args, train_loader=None, dataset_copy=None):\n",
    "    if train_loader is None or dataset_copy is None:\n",
    "        dataset_copy = get_dataset(args)\n",
    "        train_loader, _, _ = dataset_copy.get_data_loaders(args)\n",
    "    state_dict = torch.load(path)['state_dict']\n",
    "    updated_state_dict = {}\n",
    "    for key in state_dict:\n",
    "        updated_state_dict['net.'+key] = state_dict[key]\n",
    "    model.load_state_dict(updated_state_dict)\n",
    "    return model\n",
    "\n",
    "def load_models(T, args, checkpoints_dir, name_base):\n",
    "    device = 'cuda'\n",
    "    dataset_copy = get_dataset(args)\n",
    "    train_loader, _, _ = dataset_copy.get_data_loaders(args)\n",
    "    models_list = []\n",
    "    for m in range(T):\n",
    "        model_path = checkpoints_dir + name_base + str(m) + '.pth'\n",
    "        models_list.append(load_model(model_path, args, train_loader, dataset_copy))\n",
    "    return models_list\n",
    "\n",
    "def get_soup(models_list):\n",
    "    soup_model = models.get_model(args, device, len(train_loader), dataset.get_transform(args))\n",
    "    soup_dict = soup_model.state_dict()\n",
    "    other_dicts_list = [model.state_dict() for model in models_list[-3:]]\n",
    "    for key in soup_dict.keys():\n",
    "        if soup_dict[key].dtype == torch.int64:\n",
    "            new_val = other_dicts_list[0][key]\n",
    "        else:\n",
    "            new_val = torch.mean(torch.stack([d[key] for d in other_dicts_list], axis=0), axis=0)\n",
    "        soup_dict[key] = new_val\n",
    "    soup_model.load_state_dict(soup_dict)\n",
    "    return soup_model\n",
    "\n",
    "def get_accs(backbone):\n",
    "    mean_acc = 0.0\n",
    "    dataset = get_dataset(args)\n",
    "    for t in range(T):\n",
    "        train_loader, memory_loader, test_loader = dataset.get_data_loaders(args)\n",
    "        acc, acc_mask = knn_monitor(backbone, dataset, dataset.memory_loaders[t], dataset.test_loaders[t], device, args.cl_default, task_id=t, k=min(args.train.knn_k, len(memory_loader.dataset)))\n",
    "        print(acc)\n",
    "        mean_acc += acc\n",
    "    mean_acc = mean_acc / float(T)\n",
    "    print(mean_acc)\n",
    "    return mean_acc\n",
    "    \n",
    "class OutputEnsembler(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(OutputEnsembler, self).__init__()\n",
    "        self._models = models\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = torch.stack([model(x) for model in self._models], axis=0)\n",
    "        return torch.mean(outputs, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(aug_kwargs={'name': 'simsiam', 'image_size': 32}, ckpt_dir=False, cl_default=False, data_dir='../Data/', dataloader_kwargs={'drop_last': True, 'pin_memory': True, 'num_workers': 4}, dataset=<arguments.Namespace object at 0x7f6f4c3380a0>, dataset_kwargs={'dataset': 'seq-cifar10', 'data_dir': '../Data/', 'download': False, 'debug_subset_size': False}, debug=True, debug_subset_size=8, device='cuda', download=True, eval=<arguments.Namespace object at 0x7f6f4c338040>, eval_from=None, hide_progress=True, log_dir=False, logger=<arguments.Namespace object at 0x7f6f4c338670>, model=<arguments.Namespace object at 0x7f6f4c338b50>, name='simsiam-c10-experiment-resnet18', seed=None, train=<arguments.Namespace object at 0x7f6f4c3384c0>, validation=True)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "checkpoints_dir = '/u/scr/ananya/continual/UCL/checkpoints/vanilla_simsiam_cifar10/'\n",
    "name_base = 'finetune_simsiam-c10-experiment-resnet18_'\n",
    "config_path = '/u/scr/ananya/continual/logs/vanilla_simsiam_cifar10/simsiam_c10.yaml'\n",
    "args = get_args(config_path)\n",
    "print(args)\n",
    "T = 5\n",
    "models_list = load_models(T, args, checkpoints_dir, name_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.58074222668003\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "79.97997997997997\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "84.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.74369323915236\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "98.02566633761106\n",
      "89.9860163566847\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.58074222668003\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "79.97997997997997\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "84.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.74369323915236\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "98.02566633761106\n",
      "89.9860163566847\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.58074222668003\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "79.97997997997997\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "84.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.74369323915236\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "98.02566633761106\n",
      "89.9860163566847\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.58074222668003\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "79.97997997997997\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "84.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.74369323915236\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "98.02566633761106\n",
      "89.9860163566847\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.58074222668003\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "79.97997997997997\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "84.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "93.74369323915236\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "98.02566633761106\n",
      "89.9860163566847\n"
     ]
    }
   ],
   "source": [
    "all_accs = [get_accs(m.net.module.backbone) for m in models_list]\n",
    "print(np.mean(accs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soup ensembling\n",
    "soup_model = get_soup(models_list)\n",
    "mean_acc = get_accs(soup_model.net.module.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output ensembling\n",
    "output_ensemble_model = OutputEnsembler(models_list)\n",
    "mean_acc = get_accs(output_ensemble_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83.92545173, 89.24941351, 90.39585146, 89.95289182, 89.98601636])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
